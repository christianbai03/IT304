---
hide:
  - navigation
  - toc
---

# Future Recommendations

## Reducing Harmful Use of ChatGPT

### Technological Strategies

Future recommendations for using technology in a less harmful way would be rooted in technological strategies, including:

- **Fact-checking alerts**: Built-in features to flag outdated or inaccurate information.
- **Limited data collection**: Limit what data is collected from users and ensure it isn’t stored unnecessarily, enhancing privacy protections.
- **Bias audits**: Regular testing of the model for harmful stereotypes or biases.
- **Transparency tags**: Automatically label any AI-generated content to prevent deception and misinformation for users.

---

### Policy-Level Recommendations

- **Federal data protection law**: Structured from a federal government level, including mandatory disclosure when AI is used in products, services, or communication.
- **Ethics boards**: Oversight bodies that supervise companies deploying and utilizing AI technologies to ensure responsible practices.

These strategies are important because hallucinations from ChatGPT can produce misleading, erroneous text. This poses risks of spreading misinformation. Additionally, the generation of non-original text may violate copyright laws and the right to know. Biased and discriminatory text generated by ChatGPT also affects social fairness.

---

## Sources

- [The Limitations and Ethical Considerations of ChatGPT – Data Intelligence (MIT Press Direct)](https://doi.org/10.1162/dint_a_00243)  
- [ChatGPT: A New Era of AI-Powered Communication and Its Ethical Implications – Information & Management](https://doi.org/10.1016/j.im.2023.103812)
